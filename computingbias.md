---
layout: Computing Bias Popcorn Hacks 
title: Blogs
search_exclude: true
permalink: /computing/
--- 

<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Bias and Inclusivity in Technology</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            padding: 20px;
            background-color: #f4f4f4;
        }
        h2 {
            color: #333;
            border-bottom: 2px solid #666;
            padding-bottom: 5px;
        }
        .section {
            background: #fff;
            padding: 15px;
            margin-bottom: 20px;
            border-radius: 5px;
            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
        }
        ul {
            margin: 10px 0;
            padding-left: 20px;
        }
    </style>
</head>
<body>
    <div class="section">
        <h2>Provide an Example of Bias in Technology</h2>
        <p>An example of bias in software is facial recognition technology, such as early versions of systems used by companies like IBM, Microsoft, and Amazon. Studies, including one by the MIT Media Lab, found that these systems had higher error rates when identifying people with darker skin tones, especially women.</p>
        <h3>Who is Affected?</h3>
        <ul>
            <li>People of color, particularly Black and darker-skinned individuals</li>
            <li>Women, especially those with darker skin tones</li>
        </ul>
        <h3>Potential Cause of the Bias</h3>
        <p>One major cause of this bias is biased training data. Many facial recognition models are trained on datasets that contain a disproportionate number of lighter-skinned individuals, particularly white men. As a result, the model learns patterns that are more effective at identifying white faces but struggle with other demographics. This lack of diversity in training data leads to systematic inaccuracies that disproportionately affect certain groups.</p>
    </div>
    
    <div class="section">
        <h2>Popcorn Hack #2</h2>
        <p>Think about a time when you felt a technology didn't work well for you. What was the issue, and how did it make you feel? Write a short paragraph describing the experience and suggest one way the technology could be improved to be more inclusive.</p>
        <p>There was a time when I tried using voice recognition software to transcribe my notes, but it struggled to understand my words accurately, especially when I used technical terms or spoke with a slight accent. The constant misinterpretations were frustrating and made the tool feel unreliable. It felt like the software wasn’t designed with diverse speech patterns in mind. One way this technology could be improved is by training it on a wider range of voices, accents, and speech styles to ensure more accurate recognition for all users.</p>
    </div>
    
    <div class="section">
        <h2>Popcorn Hack #3</h2>
        <p>Imagine you're designing a fitness tracking app. How could bias sneak into your app’s recommendations or performance evaluations? Think about users with different physical abilities, ages, or health conditions. What features could you add to ensure the app is fair and inclusive for all users?</p>
        <p>Bias could sneak into a fitness tracking app if it assumes all users have the same physical capabilities, age-related fitness levels, or health conditions. For example, if the app sets step goals too high, it might exclude users with mobility challenges. If calorie burn estimates are based on a standard body type, they might not be accurate for older adults or individuals with different metabolic rates.</p>
        <p>To make the app more inclusive, I would add <strong>customizable goal settings</strong> that allow users to adjust recommendations based on their abilities and health conditions. The app could also include <strong>adaptive workout suggestions</strong> that cater to different fitness levels, including seated exercises or low-impact activities. Additionally, <strong>personalized health assessments</strong> could ensure that performance evaluations consider individual differences rather than using a one-size-fits-all approach.</p>
    </div>
    
    <div class="section">
        <h2>Homework Hack #1</h2>
        <p><strong>Choose a digital tool, app, or website you use regularly.</strong> It could be a social media platform, a shopping site, or a streaming service.</p>
        <h3>Identify Potential Bias</h3>
        <p>One example is social media platforms like Instagram or TikTok. These platforms use recommendation algorithms that tend to favor popular content and certain demographics. Users might notice that trending posts often feature individuals who fit conventional beauty standards, while content from smaller creators, especially those from underrepresented backgrounds, may receive less visibility.</p>
        <h3>Analyze the Cause</h3>
        <p>The bias likely comes from engagement-driven algorithms. These systems prioritize content that already has high interaction rates, reinforcing trends and making it harder for diverse content to break through. Additionally, lack of diverse testing and implicit biases in the algorithm's design can contribute to the unequal exposure of different user groups.</p>
        <h3>Propose a Solution</h3>
        <p>One way to reduce bias is by adjusting the algorithm to ensure greater visibility for diverse content. Developers could introduce features that promote a wider range of creators, such as rotating recommendations or implementing fairness filters to balance content exposure. Providing users with customizable feed settings to discover new and diverse voices could also help create a more inclusive platform.</p>
    </div>
</body>
</html>
